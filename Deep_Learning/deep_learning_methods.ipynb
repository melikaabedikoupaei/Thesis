{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c82aca5",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [Import Libraries](#section1)\n",
    "- [load Datasets](#section2)\n",
    "- [standardize the data](#section3)\n",
    "- [Methods](#section4)\n",
    "    -    [](#section41)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66fe853",
   "metadata": {},
   "source": [
    "## 1. Import necessary libraries <a id=\"section1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "104711c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras_tuner as kt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da476ed",
   "metadata": {},
   "source": [
    "## 2. Load Datasets <a id=\"section2\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a69caa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>film</th>\n",
       "      <th>date</th>\n",
       "      <th>target</th>\n",
       "      <th>rating</th>\n",
       "      <th>year</th>\n",
       "      <th>watch_count</th>\n",
       "      <th>fan_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>review_count</th>\n",
       "      <th>...</th>\n",
       "      <th>'sentiment'_Editing_negative</th>\n",
       "      <th>'sentiment'_Special_Effects_negative</th>\n",
       "      <th>'sentiment'_Other_neutral</th>\n",
       "      <th>'sentiment'_Other_negative</th>\n",
       "      <th>watchlist_length</th>\n",
       "      <th>films_watched</th>\n",
       "      <th>films_this_year</th>\n",
       "      <th>lists_created</th>\n",
       "      <th>following</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dustymoth</td>\n",
       "      <td>salems-lot-2024</td>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>104715.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14213.0</td>\n",
       "      <td>32580.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dustymoth</td>\n",
       "      <td>alien-3</td>\n",
       "      <td>2024-09-07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.82</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>487939.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>68239.0</td>\n",
       "      <td>61964.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dustymoth</td>\n",
       "      <td>lock-stock-and-two-smoking-barrels</td>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.99</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>363721.0</td>\n",
       "      <td>3624.0</td>\n",
       "      <td>96479.0</td>\n",
       "      <td>21158.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dustymoth</td>\n",
       "      <td>morocco</td>\n",
       "      <td>2024-08-21</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.58</td>\n",
       "      <td>1930.0</td>\n",
       "      <td>19531.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>4734.0</td>\n",
       "      <td>3366.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dustymoth</td>\n",
       "      <td>maxxxine</td>\n",
       "      <td>2024-08-06</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.09</td>\n",
       "      <td>2024.0</td>\n",
       "      <td>775925.0</td>\n",
       "      <td>2112.0</td>\n",
       "      <td>193118.0</td>\n",
       "      <td>254823.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2402.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_id                                film        date  target  rating  \\\n",
       "0  dustymoth                     salems-lot-2024  2024-10-06     1.0    2.39   \n",
       "1  dustymoth                             alien-3  2024-09-07     4.0    2.82   \n",
       "2  dustymoth  lock-stock-and-two-smoking-barrels  2024-09-06     0.5    3.99   \n",
       "3  dustymoth                             morocco  2024-08-21     3.0    3.58   \n",
       "4  dustymoth                            maxxxine  2024-08-06     1.5    3.09   \n",
       "\n",
       "     year  watch_count  fan_count  like_count  review_count  ...  \\\n",
       "0  2024.0     104715.0       16.0     14213.0       32580.0  ...   \n",
       "1  1992.0     487939.0      269.0     68239.0       61964.0  ...   \n",
       "2  1998.0     363721.0     3624.0     96479.0       21158.0  ...   \n",
       "3  1930.0      19531.0       63.0      4734.0        3366.0  ...   \n",
       "4  2024.0     775925.0     2112.0    193118.0      254823.0  ...   \n",
       "\n",
       "   'sentiment'_Editing_negative  'sentiment'_Special_Effects_negative  \\\n",
       "0                           0.0                                   0.0   \n",
       "1                           1.0                                   0.0   \n",
       "2                           0.0                                   0.0   \n",
       "3                           0.0                                   0.0   \n",
       "4                           0.0                                   0.0   \n",
       "\n",
       "   'sentiment'_Other_neutral  'sentiment'_Other_negative  watchlist_length  \\\n",
       "0                        0.0                         0.0              72.0   \n",
       "1                        0.0                         0.0              72.0   \n",
       "2                        0.0                         0.0              72.0   \n",
       "3                        0.0                         0.0              72.0   \n",
       "4                        0.0                         0.0              72.0   \n",
       "\n",
       "   films_watched  films_this_year  lists_created  following  followers  \n",
       "0         2402.0             48.0           84.0       32.0       26.0  \n",
       "1         2402.0             48.0           84.0       32.0       26.0  \n",
       "2         2402.0             48.0           84.0       32.0       26.0  \n",
       "3         2402.0             48.0           84.0       32.0       26.0  \n",
       "4         2402.0             48.0           84.0       32.0       26.0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the Parquet files into DataFrames\n",
    "train = pd.read_parquet(\"../Data/train.parquet\")\n",
    "test = pd.read_parquet(\"../Data/test.parquet\")\n",
    "val = pd.read_parquet(\"../Data/val.parquet\")\n",
    "train_val = pd.read_parquet(\"../Data/train_val.parquet\")\n",
    "\n",
    "# Display the first few rows of each DataFrame to confirm\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb97896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>param</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'max_depth': '10'}</td>\n",
       "      <td>0.906551</td>\n",
       "      <td>0.821834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 50, 'n_estim...</td>\n",
       "      <td>0.881634</td>\n",
       "      <td>0.777278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential',...</td>\n",
       "      <td>0.915916</td>\n",
       "      <td>0.838903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoostRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.858019</td>\n",
       "      <td>0.736197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name                                              param  \\\n",
       "0  DecisionTreeRegressor                                {'max_depth': '10'}   \n",
       "1  RandomForestRegressor  {'max_depth': 20, 'max_features': 50, 'n_estim...   \n",
       "2      AdaBoostRegressor  {'learning_rate': 0.01, 'loss': 'exponential',...   \n",
       "3       XGBoostRegressor  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...   \n",
       "\n",
       "       rmse       mse  \n",
       "0  0.906551  0.821834  \n",
       "1  0.881634  0.777278  \n",
       "2  0.915916  0.838903  \n",
       "3  0.858019  0.736197  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=pd.read_csv(\"../Data/results.csv\", index_col=0)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c8af2c",
   "metadata": {},
   "source": [
    "## 3. standardize the data <a id=\"section3\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0caae3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any NaN values\n",
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "val = val.dropna()\n",
    "train_val = train_val.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a871eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'target'\n",
    "\n",
    "# Separate the target column from the features\n",
    "train_features = train.drop(columns=[target_column])\n",
    "val_features = val.drop(columns=[target_column])\n",
    "\n",
    "# Separate numeric columns\n",
    "numeric_cols = train_features.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the numeric columns of the train data and transform both train and validation sets\n",
    "train_features_scaled = train_features.copy()\n",
    "val_features_scaled = val_features.copy()\n",
    "\n",
    "train_features_scaled[numeric_cols] = scaler.fit_transform(train_features[numeric_cols])\n",
    "val_features_scaled[numeric_cols] = scaler.transform(val_features[numeric_cols])\n",
    "\n",
    "# Add the target column back to the scaled features\n",
    "train_scaled = pd.concat([train_features_scaled, train[target_column]], axis=1)\n",
    "val_scaled = pd.concat([val_features_scaled, val[target_column]], axis=1)\n",
    "\n",
    "# ⭐ CORRECT PART HERE\n",
    "X_train = train_scaled[numeric_cols]\n",
    "y_train = train_scaled[target_column]\n",
    "\n",
    "X_val = val_scaled[numeric_cols]\n",
    "y_val = val_scaled[target_column]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86224b58",
   "metadata": {},
   "source": [
    "## Methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b5e1ea",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b3d22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\melika\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m15716/15716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 4.6294\n",
      "Epoch 2/5\n",
      "\u001b[1m15716/15716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - loss: 0.7836\n",
      "Epoch 3/5\n",
      "\u001b[1m15716/15716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - loss: 0.7830\n",
      "Epoch 4/5\n",
      "\u001b[1m15716/15716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 0.7830\n",
      "Epoch 5/5\n",
      "\u001b[1m15716/15716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 1ms/step - loss: 0.7839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x212cc047f50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a simple model without hidden layers (just input -> output)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=(X_train.shape[1],))\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26b0d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\melika\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m15716/15716\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 12ms/step - loss: 1.1831\n",
      "Epoch 2/5\n",
      "\u001b[1m 8920/15716\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m1:20\u001b[0m 12ms/step - loss: 0.8125"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define the RNN model\n",
    "model_rnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(64, input_shape=(X_train.shape[1], 1)),  # RNN layer with 64 units\n",
    "    tf.keras.layers.Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_rnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_rnn.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f24cf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model_cnn = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(64, 3, activation='relu', input_shape=(X_train.shape[1], 1)),  # Conv layer with 64 filters\n",
    "    tf.keras.layers.MaxPooling1D(2),  # Pooling layer to reduce dimensionality\n",
    "    tf.keras.layers.Flatten(),  # Flatten the data to feed into a dense layer\n",
    "    tf.keras.layers.Dense(1)  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mse'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model_cnn.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e64ec014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
      "Mean Squared Error (MSE): 0.8251\n",
      "Root Mean Squared Error (RMSE): 0.9084\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val).flatten()  # flatten to make it 1D\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9221219a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>param</th>\n",
       "      <th>rmse</th>\n",
       "      <th>mse</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>{'max_depth': '10'}</td>\n",
       "      <td>0.906551</td>\n",
       "      <td>0.821834</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>{'max_depth': 20, 'max_features': 50, 'n_estim...</td>\n",
       "      <td>0.881634</td>\n",
       "      <td>0.777278</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential',...</td>\n",
       "      <td>0.915916</td>\n",
       "      <td>0.838903</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoostRegressor</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 7, 'n_esti...</td>\n",
       "      <td>0.858019</td>\n",
       "      <td>0.736197</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TensorFlowLinearModel</td>\n",
       "      <td>{'epochs': 5, 'batch_size': 32, 'learning_rate...</td>\n",
       "      <td>0.908365</td>\n",
       "      <td>0.825127</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_name                                              param  \\\n",
       "0  DecisionTreeRegressor                                {'max_depth': '10'}   \n",
       "1  RandomForestRegressor  {'max_depth': 20, 'max_features': 50, 'n_estim...   \n",
       "2      AdaBoostRegressor  {'learning_rate': 0.01, 'loss': 'exponential',...   \n",
       "3       XGBoostRegressor  {'learning_rate': 0.1, 'max_depth': 7, 'n_esti...   \n",
       "4  TensorFlowLinearModel  {'epochs': 5, 'batch_size': 32, 'learning_rate...   \n",
       "\n",
       "       rmse       mse  Unnamed: 0  \n",
       "0  0.906551  0.821834         NaN  \n",
       "1  0.881634  0.777278         NaN  \n",
       "2  0.915916  0.838903         NaN  \n",
       "3  0.858019  0.736197         NaN  \n",
       "4  0.908365  0.825127         4.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attach result to result dataframe\n",
    "# Create a new row\n",
    "new_row = {\n",
    "    'Unnamed: 0': len(results),\n",
    "    'model_name': 'TensorFlowLinearModel',\n",
    "    'param': {\"epochs\":5, \"batch_size\":32,\"learning_rate\":0.001,\"hidden_layer\":{}},  # No real hyperparameters for this simple linear model\n",
    "    'rmse': rmse,\n",
    "    'mse': mse\n",
    "}\n",
    "\n",
    "# Append the new row\n",
    "results = pd.concat([results, pd.DataFrame([new_row])], ignore_index=True)\n",
    "# Show updated DataFrame\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d18b1d",
   "metadata": {},
   "source": [
    "## add hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfb1ed1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\melika\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m14145/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.8804 - val_loss: 0.8140\n",
      "Epoch 2/5\n",
      "\u001b[1m14145/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.7820 - val_loss: 0.8119\n",
      "Epoch 3/5\n",
      "\u001b[1m14145/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.7729 - val_loss: 0.8106\n",
      "Epoch 4/5\n",
      "\u001b[1m14145/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.7733 - val_loss: 0.8063\n",
      "Epoch 5/5\n",
      "\u001b[1m14145/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.7724 - val_loss: 0.8167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2131fc6b090>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define a simple model without hidden layers (just input -> output)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(100, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1, validation_split=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cf894bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m311/311\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Mean Squared Error (MSE): 0.8284\n",
      "Root Mean Squared Error (RMSE): 0.9102\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "y_pred = model.predict(X_val).flatten()  # flatten to make it 1D\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6611406c",
   "metadata": {},
   "source": [
    "## Wide and Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec9d5ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\melika\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_5']\n",
      "Received: inputs=Tensor(shape=(None, 92))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14123/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\melika\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor_5']\n",
      "Received: inputs=Tensor(shape=(None, 92))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14145/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 0.9086 - val_loss: 0.8881\n",
      "Epoch 2/5\n",
      "\u001b[1m14145/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 0.8035 - val_loss: 0.8416\n",
      "Epoch 3/5\n",
      "\u001b[1m14145/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.8020 - val_loss: 0.8320\n",
      "Epoch 4/5\n",
      "\u001b[1m14145/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.7998 - val_loss: 0.8353\n",
      "Epoch 5/5\n",
      "\u001b[1m14145/14145\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2ms/step - loss: 0.7951 - val_loss: 0.8244\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2131fc57090>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "input = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(10, activation=\"relu\")(input)\n",
    "hidden2 = keras.layers.Dense(10, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input], outputs=[output])\n",
    "# Compile the model\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4309937d",
   "metadata": {},
   "source": [
    "## tune hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b145addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0daacc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(1))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\")\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc6fa3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 05m 02s]\n",
      "val_loss: 0.9118149280548096\n",
      "\n",
      "Best val_loss So Far: 0.7890414595603943\n",
      "Total elapsed time: 12h 52m 17s\n",
      "Best Hyperparameters: {'units_1': 224, 'num_hidden_layers': 3, 'units_2': 128, 'learning_rate': 0.0016702505037489304, 'units_3': 192, 'units_4': 224, 'tuner/epochs': 10, 'tuner/initial_epoch': 4, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0021'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\melika\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define the HyperModel\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = Sequential()\n",
    "        \n",
    "        # Add the input layer (first layer)\n",
    "        model.add(Dense(units=hp.Int('units_1', min_value=32, max_value=256, step=32),\n",
    "                        activation='relu', input_shape=(X_train.shape[1],)))\n",
    "        \n",
    "        # Add additional hidden layers if needed\n",
    "        for i in range(hp.Int('num_hidden_layers', 1, 3)):  # Search between 1 and 3 hidden layers\n",
    "            model.add(Dense(units=hp.Int(f'units_{i+2}', min_value=32, max_value=256, step=32),\n",
    "                            activation='relu'))\n",
    "        \n",
    "        # Add the output layer\n",
    "        model.add(Dense(1))\n",
    "        \n",
    "        # Compile the model\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='LOG', default=1e-3)),\n",
    "                      loss='mean_squared_error')\n",
    "        \n",
    "        return model\n",
    "\n",
    "# Instantiate the HyperModel\n",
    "hypermodel = MyHyperModel()\n",
    "\n",
    "# Instantiate the tuner (using Hyperband, but you could also use RandomSearch)\n",
    "tuner = kt.Hyperband(hypermodel, \n",
    "                     objective='val_loss', \n",
    "                     max_epochs=10, \n",
    "                     factor=3, \n",
    "                     directory='my_dir', \n",
    "                     project_name='hyperparameter_tuning')\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Get the best model and hyperparameters\n",
    "best_model = tuner.get_best_models()[0]\n",
    "best_hyperparameters = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_hyperparameters.values)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
